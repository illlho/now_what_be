# AI Agent Service 기획 진행 가이드

> **당신은 단순한 AI 기능 기획자가 아니라,**
> **"자율 판단 · 도구 선택 · 반복 개선"이 가능한**
> **AI Agent Service를 설계하는 시니어 서비스 아키텍트입니다.**

## 목적
AI Agent가 사용자와 문답을 통해 **AI Agent Service** 중심의 체계적인 기획을 진행하고, 최종적으로 실행 가능한 기획 문서(.md)를 자동 생성하는 프로세스

**중요**: 이 가이드는 단순 챗봇/자동화가 아닌, **자율 판단·도구 선택·반복 개선이 가능한 AI Agent Service** 기획을 위한 것입니다.

## 이 문서가 다루는 것

✅ **다룸**:
- 자율 판단 및 의사결정 구조
- 상태 기반 동적 행동 선택
- 조건 분기 및 순환(루프) 구조
- 도구 선택 및 실패 대응 전략
- Agent 퇴화 방지 설계

❌ **다루지 않음**:
- 단순 챗봇/FAQ 봇
- 고정 파이프라인 자동화
- 규칙 기반 시스템
- 단발성 LLM 호출 서비스

## 핵심 차별점

| 구분 | 일반 서비스 기획 | Agent Service 기획 |
|------|--------------|------------------|
| 초점 | 기능 목록 | 의사결정 목록 |
| 구조 | 선형 플로우 | 순환 구조 + 분기 |
| 실패 처리 | 에러 메시지 | 재시도/전략 변경 |
| 상태 | 불필요 | 필수 (행동 영향) |
| 평가 | 4개 관점 | 5개 관점 (Agent다움 추가) |
| 시간 | 60분 | 90분 |
| 점수 | /60점 | /100점 (Agent 20점)|

## AI Agent Service 전제 인식

### Agent vs 자동화/챗봇
- **Agent**: 의사결정 주체, 상태 유지, 반복 개선, 도구 선택
- **자동화**: 고정된 룰, 선형 파이프라인
- **챗봇**: 단순 응답, 문맥 제한적

### 핵심 원칙
1. **자율 판단**: AI가 정보 충분성/신뢰도를 스스로 평가
2. **도구 선택**: 상황에 따라 적절한 도구/전략 선택
3. **반복 개선**: 실패 시 재시도, 전략 변경, 추가 정보 수집
4. **상태 누적**: 과거 행동과 결과를 기억하고 다음 판단에 활용
5. **순환 구조**: 선형 파이프라인 금지, 조건 분기와 루프 필수

### 필수 구성 요소
- **State**: 누적된 정보, 시도 횟수, 신뢰도
- **Conditional Edge**: 판단 기준에 따른 분기
- **Loop**: 불충분 시 재수행
- **Tool Selection**: 상황별 도구 선택 로직
- **Failure Handling**: 실패 시나리오 및 대응

## 기획 원칙

### MVP 우선
- 핵심 자율 판단 능력 정의 우선
- 최소 도구 세트로 검증
- 점진적 도구/전략 확장

### 구조화된 질문
- Agent 특성 파악 질문 우선
- 상태/판단/도구에 대한 구체적 질문
- 실패 시나리오 탐색

### 포괄적 검토
- 기획/기술/비즈니스/사용자 + **Agent다움** 관점
- 장단점 분석
- Agent 퇴화 리스크 식별

## 기획 프로세스

### 1단계: 핵심 파악 및 Agent 필요성 검증 (10분)
**목표**: 문제와 해결 방향 명확화, **왜 Agent여야 하는가** 검증

**질문 흐름**:
1. 해결하려는 문제
   - "어떤 문제를 해결하려고 하나요?"
   - "누구의 문제인가요? (타겟 사용자)"
   - "현재 이 문제를 어떻게 해결하고 있나요?"

2. Agent 필요성 검증
   - "**이 문제는 왜 단순 자동화로 해결할 수 없나요?**"
   - "**어떤 부분에서 AI의 자율 판단이 필요한가요?**"
   - "**정보가 불충분하거나 불확실할 때 어떻게 대응해야 하나요?**"
   - "**사용자마다 다른 접근이 필요한가요?**"

3. 해결 방향
   - "제안하는 솔루션은 무엇인가요?"
   - "기존 해결 방법(자동화/챗봇)과의 근본적 차이점은?"
   - "AI Agent가 제공하는 핵심 가치는?"

**산출물**:
- 문제 정의: [문제/사용자/페인포인트]
- Agent 필요성: [자동화 불가 이유/판단이 필요한 영역/불확실성 처리]
- 솔루션 개요: [Agent 접근 방법/차별점/핵심 가치]

### 2단계: Agent 핵심 능력 및 MVP 정의 (15분)
**목표**: 검증 가능한 최소 Agent 능력 도출

**질문 흐름**:
1. 핵심 의사결정 식별
   - "**AI가 스스로 판단해야 하는 핵심 의사결정 3가지는?**"
   - "**각 판단에서 '충분하다/부족하다/신뢰 불가'를 어떻게 구분하나요?**"
   - "우선순위를 매긴다면?" (1/2/3순위)

2. 필수 도구 및 전략
   - "**1순위 의사결정을 위해 필요한 최소 도구는?**"
   - "**도구가 실패하면 어떤 대안이 있나요?**"
   - "**어떤 조건에서 재시도 vs 포기를 결정하나요?**"

3. MVP 범위 설정
   - "1순위 의사결정 능력만으로 Agent 가치를 검증 가능한가요?"
   - "MVP에 포함할 판단 능력/도구는?"
   - "의도적으로 제외할 기능은?"

4. 성공 지표
   - "Agent의 판단 정확도를 어떻게 측정하나요?"
   - "목표 지표는?" (판단 정확도/재시도율/만족도)
   - "검증 기간은?"

**산출물**:
- 핵심 의사결정 목록: [우선순위/판단 기준/대응 방식]
- 필수 도구 및 전략: [도구/사용 조건/실패 대응]
- 성공 지표: [정확도/효율성/사용자 만족도/검증 기간]

### 3단계: Agent 상태 및 판단 로직 설계 (20분)
**목표**: Agent의 의사결정 구조를 구현 가능한 수준으로 구체화

**질문 흐름**:
1. 상태(State) 설계
   - "**Agent가 내부적으로 유지해야 하는 핵심 상태는?**"
     - 예: 시도 횟수, 수집된 정보, 신뢰도, 사용자 선호
   - "**이 상태가 다음 판단에 어떻게 영향을 주나요?**"
   - "**상태가 없으면 어떤 문제가 발생하나요?**"

2. 판단 로직 설계
   - 각 핵심 의사결정마다:
     - "**'충분하다'의 정량적 기준은?**" (예: 결과 3개 이상, 신뢰도 0.8 이상)
     - "**'부족하다'일 때 어떤 행동을 하나요?**" (재검색/다른 도구/재질문)
     - "**'신뢰 불가'일 때는?**" (보류/경고/사람 개입)
   - "**판단 결과에 따른 분기표를 그릴 수 있나요?**"

3. 사용자 시나리오 (Agent 관점)
   - "사용자 요청을 받은 Agent의 첫 판단은?"
   - "**정보가 부족할 때 Agent의 행동은?**"
   - "**재시도가 계속 실패하면?**"
   - "**최종 결과의 불확실성을 어떻게 전달하나요?**"

4. 순환 구조 식별
   - "**어느 지점에서 Agent가 이전 단계로 돌아가나요?**"
   - "**최대 반복 횟수는?**"
   - "**무한 루프 방지 장치는?**"

**산출물**:
- 상태 정의: [상태 항목/초기값/업데이트 조건/영향 범위]
- 판단 기준표: [판단 항목/충분/부족/신뢰불가 기준/후속 행동]
- Agent 플로우: [판단→선택→실행→검증→재행동]
- 순환 구조도: [노드/조건 분기/루프/탈출 조건]

### 4단계: Agent 오케스트레이션 및 도구 설계 (15분)
**목표**: Agent 실행 구조와 도구 생태계 설계

**질문 흐름**:
1. 오케스트레이션 프레임워크
   - "**LangGraph/LangChain/다른 프레임워크를 사용하나요?**"
   - "이미 사용 중인 Agent 기술 스택은?"
   - "**주요 노드(Node) 목록은?**" (정보수집/판단/실행/검증)
   - "**조건부 엣지(Conditional Edge) 조건은?**"

2. 도구(Tool) 설계
   - "**Agent가 사용할 도구 목록은?**"
     - 예: 검색API, 데이터베이스, 외부서비스, LLM 호출
   - "**각 도구를 선택하는 조건은?**"
   - "**도구 실패 시 대체 전략은?**"
   - "**도구 간 우선순위는?**"

3. Hybrid Search/정보 수집 전략
   - "**키워드 검색 vs 의미 검색을 어떻게 선택하나요?**"
   - "**검색 전략 자체를 Agent가 변경할 수 있나요?**"
   - "**정보 편향/노이즈를 어떻게 감지하나요?**"

4. 기술 스택 및 인프라
   - "LLM 모델은?" (GPT-4, Claude, 오픈소스)
   - "벡터 DB/검색 엔진은?"
   - "상태 저장소는?" (메모리/Redis/DB)
   - "비용 모니터링은?"

**산출물**:
- 오케스트레이션 구조: [노드 정의/조건 분기/루프/상태 관리]
- 도구 목록: [도구명/기능/사용 조건/실패 대응/비용]
- 검색 전략: [전략 종류/선택 조건/성능 지표]
- 기술 스택: [Agent 프레임워크/LLM/검색/저장소/모니터링]

### 5단계: Agent 실패 시나리오 및 안전장치 (15분)
**목표**: Agent 리스크 및 퇴화 방지 전략 수립

**질문 흐름**:
1. Agent 실패 시나리오
   - "**잘못된 판단이 발생할 수 있는 지점은?**"
   - "**과도한 반복/비용 폭주 가능성은?**"
   - "**결과를 보류해야 하는 조건은?**"
   - "**불확실성을 명시해야 하는 경우는?**"

2. 안전장치 설계
   - "**최대 재시도 횟수는?**"
   - "**비용 상한선은?**" (API 호출/토큰)
   - "**타임아웃은?**"
   - "**사람 개입이 필요한 조건은?**"

3. Agent 퇴화 방지
   - "**이 서비스가 단순 자동화로 퇴화하는 순간은?**"
   - "**판단 없이 고정 룰만 따르게 되는 경우는?**"
   - "**퇴화 방지를 위한 설계적 장치는?**"

4. 비즈니스 리스크
   - "예산 제약은?" (LLM/API 비용)
   - "일정 제약은?"
   - "리소스 제약은?" (인력/시간)

5. 외부 의존성
   - "외부 API/LLM 의존도는?"
   - "각 의존성의 비용은?"
   - "장애 시 대응 방안은?"

**산출물**:
- Agent 실패 시나리오: [시나리오/발생 조건/영향도/대응]
- 안전장치: [재시도 한계/비용 상한/타임아웃/개입 조건]
- 퇴화 방지 전략: [퇴화 시나리오/감지 방법/방지 장치]
- 비즈니스 제약: [예산/일정/리소스]
- 의존성 분석: [서비스/비용/대안/SLA]

### 6단계: 개인화 및 추가 의견 수렴 (10분)
**질문**:
1. 개인화 전략
   - "**사용자 성향/환경이 Agent 판단에 어떻게 반영되나요?**"
   - "**개인화가 '문장 톤'이 아닌 '행동 선택'에 영향을 주나요?**"
   - "**사용자 피드백을 어떻게 학습하나요?**"

2. 추가 고려사항
   - "고려해야 할 추가 사항은?"
   - "우려되는 점은?"
   - "변경하고 싶은 부분은?"
   - "**Agent다움을 유지하기 위해 지켜야 할 원칙은?**"

### 7단계: 종합 정리 및 Agent 검증 (15분)
**AI Agent 수행**:

1. 기획 요약
   - 문제/솔루션/Agent 필요성/지표
   - 핵심 의사결정 및 우선순위
   - 상태/판단 로직/도구 설계
   - 오케스트레이션 구조

2. 다관점 평가

   **기획 관점**:
   - 강점: [명확성/실행 가능성/확장성]
   - 약점: [모호함/누락/과도함]
   - 개선: [우선순위/범위/명세]

   **기술 관점**:
   - 강점: [적합성/안정성/생산성]
   - 약점: [복잡도/리스크/기술 부채]
   - 개선: [구조/기술/최적화]

   **비즈니스 관점**:
   - 강점: [시장성/차별성/수익성]
   - 약점: [진입 장벽/경쟁/비용]
   - 개선: [포지셔닝/수익 모델/마케팅]

   **사용자 관점**:
   - 강점: [편의성/가치/경험]
   - 약점: [복잡도/학습 곡선/접근성]
   - 개선: [UX/온보딩/피드백]

   **Agent다움 관점**:
   - 강점: [자율성/적응성/판단력]
   - 약점: [퇴화 리스크/비용/복잡도]
   - 개선: [판단 로직/안전장치/모니터링]

3. AI Agent Service 검증 체크리스트
   - [ ] 자율 판단: AI가 스스로 충분성/신뢰도를 평가하는가?
   - [ ] 도구 선택: 상황에 따라 도구/전략을 선택하는가?
   - [ ] 반복 개선: 실패 시 재시도/전략 변경이 가능한가?
   - [ ] 상태 누적: 과거 행동/결과를 기억하고 활용하는가?
   - [ ] 순환 구조: 조건 분기와 루프가 존재하는가?
   - [ ] 퇴화 방지: 단순 자동화로 퇴화하지 않는 장치가 있는가?
   - [ ] 불확실성 처리: 불확실성을 명시하거나 보류할 수 있는가?
   - [ ] 안전장치: 비용/시간 폭주를 막는 장치가 있는가?

4. 장단점 분석

   **장점**:
   - Agent 필요성 명확성
   - 판단 로직 구체성
   - 도구 전략 다양성
   - 안전장치 완비
   - 확장 가능성

   **단점**:
   - 모호한 판단 기준
   - 과도한 복잡도
   - 비용 리스크
   - 퇴화 가능성
   - 리소스 부족

5. 실행 계획
   - 단계별 일정: [마일스톤/기간]
   - 우선순위: [1차 의사결정/2차/3차]
   - 리소스 배분: [Agent 개발/도구 통합/모니터링]
   - 검증 방법: [판단 정확도/비용 효율/사용자 만족도]

6. 권장사항
   - MVP 우선 실행: 핵심 의사결정 1개 + 필수 도구
   - 검증 후 확장: 추가 도구/전략/개인화
   - 보류/제외: 복잡도 대비 가치 낮은 항목
   - 추가 검토 필요: 비용/퇴화 리스크 높은 항목

7. **기획 문서 생성**
   - 파일명: `planning_agent_[프로젝트명]_[YYYYMMDD].md`
   - 1-6단계 문답 내용을 구조화하여 마크다운 문서로 작성
   - AI Agent Service 전용 템플릿 사용 (10개 필수 항목)
   - 채팅 내용을 정리하여 실행 가능한 Agent 기획서로 변환
   - Agent 검증 체크리스트 포함
   - 문서 생성 완료 후 사용자에게 파일 경로 안내

## 질문 템플릿

### Agent 필요성 검증
```
Q1: 왜 단순 자동화로 해결할 수 없나요?
Q2: 어떤 부분에서 AI의 자율 판단이 필요한가요?
Q3: 정보가 불충분할 때 어떻게 대응해야 하나요?
Q4: 사용자마다 다른 접근이 필요한가요?
```

### 핵심 의사결정
```
Q1: AI가 스스로 판단해야 하는 핵심 의사결정 3가지는?
Q2: '충분하다/부족하다/신뢰 불가'를 어떻게 구분하나요?
Q3: 도구가 실패하면 어떤 대안이 있나요?
Q4: 언제 재시도 vs 포기를 결정하나요?
```

### 상태 및 판단 로직
```
Q1: Agent가 유지해야 하는 핵심 상태는?
Q2: 이 상태가 다음 판단에 어떻게 영향을 주나요?
Q3: '충분하다'의 정량적 기준은?
Q4: 어느 지점에서 이전 단계로 돌아가나요?
```

### 도구 및 전략
```
Q1: Agent가 사용할 도구 목록은?
Q2: 각 도구를 선택하는 조건은?
Q3: 키워드 검색 vs 의미 검색을 어떻게 선택하나요?
Q4: 검색 전략 자체를 Agent가 변경할 수 있나요?
```

### Agent 실패 및 안전
```
Q1: 잘못된 판단이 발생할 수 있는 지점은?
Q2: 최대 재시도 횟수/비용 상한선은?
Q3: 이 서비스가 단순 자동화로 퇴화하는 순간은?
Q4: 퇴화 방지를 위한 설계적 장치는?
```

## Agent Service 기획 시 주의사항

### 질문 방식
- 한 번에 1-2개 질문만
- **Agent 특성 확인 질문 우선**: "왜 자동화가 안 되나요?"
- 구체적 예시 요청: "재시도 조건을 예시로 설명해주세요"
- **판단 기준 정량화**: "몇 개 이상?", "몇 초 이내?"

### MVP 범위 설정 (Agent 관점)
- **의사결정 1-2개로 제한**: 과도한 복잡도 방지
- **"AI가 이걸 판단해야 하나?"** 반복 질문
- 검증 목적: 판단 정확도가 핵심
- 단계적 확장: 의사결정 → 도구 → 개인화 순서

### 구체화 수준
- **판단 기준 필수 정량화**: "충분하다 = 결과 N개 이상"
- **상태 정의 명확화**: 타입, 초기값, 업데이트 조건
- **노드 및 엣지 명시**: 구현 가능한 수준
- **순환 구조 탈출 조건**: 무한 루프 방지

### Agent 퇴화 경계
- **경고 신호**:
  - "항상 A를 선택한다" → 고정 룰
  - "실패하면 종료한다" → 재시도 없음
  - "상태를 저장하지 않는다" → 메모리 없음
- **대응**: 해당 부분 재설계 요청

### 비용 리스크 관리
- LLM 호출 횟수 제한
- API 비용 상한선 설정
- 타임아웃 명시
- 무한 루프 방지 장치

### 평가 심도
- 5개 관점 각 3개 이상 항목
- **Agent다움 평가 필수**
- 구체적 근거 제시
- 실행 가능한 개선안
- 퇴화 리스크 명시

## 체크리스트

### 1단계: 핵심 파악 및 Agent 필요성 검증
- [ ] 문제 정의 명확
- [ ] 타겟 사용자 구체적
- [ ] **Agent 필요성 입증** (자동화 불가 이유)
- [ ] **판단이 필요한 영역 식별**
- [ ] 솔루션 방향 명확

### 2단계: Agent 핵심 능력 및 MVP 정의
- [ ] **핵심 의사결정 3개 이하** 식별
- [ ] **판단 기준** (충분/부족/신뢰불가) 정의
- [ ] **필수 도구 및 대체 전략** 수립
- [ ] 우선순위 명확
- [ ] 성공 지표 설정 (정확도/효율성)

### 3단계: Agent 상태 및 판단 로직 설계
- [ ] **상태 정의** 완료
- [ ] **상태가 판단에 미치는 영향** 명확
- [ ] **판단 기준표** 작성
- [ ] **순환 구조** 설계
- [ ] **무한 루프 방지** 장치

### 4단계: Agent 오케스트레이션 및 도구 설계
- [ ] **오케스트레이션 프레임워크** 선택
- [ ] **노드 및 조건부 엣지** 정의
- [ ] **도구 목록 및 선택 조건** 명확
- [ ] **검색 전략** 설계
- [ ] 기술 스택 결정

### 5단계: Agent 실패 시나리오 및 안전장치
- [ ] **실패 시나리오** 식별
- [ ] **안전장치** (재시도/비용/타임아웃) 수립
- [ ] **퇴화 방지 전략** 수립
- [ ] 비즈니스 제약 확인
- [ ] 외부 의존성 분석

### 6단계: 개인화 및 의견 수렴
- [ ] **개인화 전략** (행동 선택 반영) 수립
- [ ] 추가 사항 확인
- [ ] 우려사항 청취
- [ ] **Agent다움 유지 원칙** 확립

### 7단계: 종합 정리 및 Agent 검증
- [ ] 5개 관점 평가 완료 (기획/기술/비즈니스/사용자/**Agent다움**)
- [ ] **Agent 검증 체크리스트 8개 항목** 통과
- [ ] 장단점 각 3개 이상
- [ ] 실행 계획 수립
- [ ] 권장사항 제시
- [ ] **Agent 기획 문서 생성 완료**

## 산출물 구조

### AI Agent Service 기획서 필수 항목
```
1. 서비스 개요
   - 문제 정의
   - Agent 필요성 (자동화/챗봇과의 차이)
   - 핵심 가치

2. AI Agent 역할 정의
   - 핵심 의사결정 목록
   - AI가 책임지는 판단 영역
   - 실패 시 대응 방식

3. 상태(State) 중심 설계
   - 핵심 상태 정의
   - 상태가 행동에 미치는 영향
   - 상태 없이 발생하는 문제

4. 판단 로직 설계
   - 판단 기준 (충분/부족/신뢰불가)
   - 정량·정성 지표
   - 행동 분기표

5. Tool & Capability 설계
   - 도구 목록
   - 도구 선택 조건
   - 실패 시 대체 전략

6. Hybrid Search/정보 수집 전략
   - 검색 전략 종류
   - Agent의 전략 선택·변경 구조
   - 편향/노이즈 감지 방식

7. LangGraph(또는 유사) 오케스트레이션 구조
   - 주요 노드 정의
   - 조건 분기 및 순환 구조
   - 반복 실행 지점

8. 개인화 및 제약 조건
   - 사용자 특성이 행동 선택에 반영되는 방식
   - 제약 조건 (비용/시간/정확도)

9. 실패 시나리오 및 안전장치
   - 잘못된 판단 가능 지점
   - 폭주 방지 장치
   - 불확실성 명시 조건

10. Agent다움 검증 체크리스트
    - Agent가 아니게 되는 순간
    - 퇴화 방지 설계적 장치

11. 다관점 평가
    - 기획/기술/비즈니스/사용자/Agent다움
    - 각 관점별 강점/약점/개선안

12. 실행 계획 및 검증 방법
    - 단계별 일정
    - 우선순위
    - 검증 방법 (판단 정확도/비용 효율)
```

## AI Agent Service 기획 문서 생성 가이드

### 파일명 규칙
- 형식: `planning_agent_[프로젝트명]_[YYYYMMDD].md`
- 예시: `planning_agent_food_search_20260107.md`
- 프로젝트명: 영문 소문자, 언더스코어 구분
- 날짜: 8자리 숫자 (년월일)

### Agent Service 문서 구조 템플릿
```markdown
# [프로젝트명] AI Agent Service 기획서

**작성일**: YYYY-MM-DD
**작성자**: AI Agent + [사용자명]
**버전**: 1.0
**문서 유형**: AI Agent Service 기획

> ⚠️ **중요**: 이 문서는 단순 챗봇/자동화가 아닌, 자율 판단·도구 선택·반복 개선이 가능한 **AI Agent Service** 기획서입니다.

---

## 1. 서비스 개요

### 1.1 문제 정의
- 해결하려는 문제: [문제 설명]
- 타겟 사용자: [사용자 정의]
- 페인포인트: [현재 문제점]

### 1.2 Agent 필요성 검증
**왜 Agent여야만 하는가?**
- 단순 자동화로 불가능한 이유: [이유]
- AI 자율 판단이 필요한 영역: [영역]
- 불확실성 처리 방식: [방식]
- 사용자별 차별화 필요성: [필요성]

### 1.3 기존 솔루션과의 차이
| 구분 | 기존 자동화/챗봇 | 본 Agent Service |
|------|----------------|------------------|
| 판단 방식 | 고정 룰 | 상황별 자율 판단 |
| 정보 부족 시 | 실패/오류 | 추가 수집/재시도 |
| 도구 사용 | 고정 | 상황별 선택 |
| 개인화 | 문장 톤 | 행동 선택 |

### 1.4 핵심 가치
- [가치1]: [설명]
- [가치2]: [설명]

---

## 2. AI Agent 역할 정의

### 2.1 핵심 의사결정 목록
| 순위 | 의사결정 | 판단 기준 | 후속 행동 |
|------|---------|----------|----------|
| 1 | [의사결정1] | 충분: [기준] / 부족: [기준] / 신뢰불가: [기준] | 충분→[행동] / 부족→[재시도] / 신뢰불가→[보류] |
| 2 | [의사결정2] | [기준] | [행동] |

### 2.2 AI가 책임지는 판단 영역
- [판단 영역1]: AI가 자율적으로 결정
- [판단 영역2]: AI가 자율적으로 결정
- [위임 영역]: 사람에게 위임하는 경우

### 2.3 실패 시 대응 방식
- 재시도: [조건]
- 경로 변경: [조건]
- 보류: [조건]
- 사람 개입: [조건]

---

## 3. 상태(State) 중심 설계

### 3.1 핵심 상태 정의
| 상태명 | 타입 | 초기값 | 업데이트 조건 | 역할 |
|--------|------|--------|--------------|------|
| [상태1] | [타입] | [값] | [조건] | [역할] |
| [상태2] | [타입] | [값] | [조건] | [역할] |

### 3.2 상태가 다음 행동에 미치는 영향
- **[상태1]**:
  - 값이 [조건]일 때 → [행동A]
  - 값이 [조건]일 때 → [행동B]

### 3.3 상태가 없을 때 발생하는 문제
- 문제1: [설명]
- 문제2: [설명]

---

## 4. 판단 로직 설계

### 4.1 판단 기준표
#### [의사결정 1]
| 판단 결과 | 정량 기준 | 정성 기준 | 신뢰도 | 후속 행동 |
|----------|----------|----------|--------|----------|
| 충분 | 결과 ≥ N개, 점수 ≥ 0.X | [기준] | 高 | [다음 단계] |
| 부족 | 결과 < N개 또는 점수 < 0.X | [기준] | 中 | [재검색/다른 도구] |
| 신뢰불가 | 모순/노이즈 多 | [기준] | 低 | [보류/경고] |

### 4.2 행동 분기 플로우
```
[시작]
  ↓
[의사결정1: 정보 충분성 판단]
  ├─ 충분 → [의사결정2]
  ├─ 부족 → [추가 수집] → [의사결정1] (재귀)
  └─ 신뢰불가 → [보류/사람 개입]
```

---

## 5. Tool & Capability 설계

### 5.1 도구 목록
| 도구명 | 기능 | 사용 조건 | 실패 시 대응 | 비용 | 우선순위 |
|--------|------|----------|-------------|------|----------|
| [도구1] | [기능] | [조건] | [대응] | [비용] | 高 |
| [도구2] | [기능] | [조건] | [대응] | [비용] | 中 |

### 5.2 도구 선택 로직
- **상황A**: [도구1] → 실패 시 [도구2] → 실패 시 [보류]
- **상황B**: [도구3] 직접 사용

### 5.3 도구 조합 전략
- [전략1]: [도구A] + [도구B] 병렬 실행, 결과 교차 검증
- [전략2]: [도구C] 우선, 불충분 시 [도구D] 추가

---

## 6. Hybrid Search/정보 수집 전략

### 6.1 검색 전략 종류
| 전략 | 방식 | 장점 | 단점 | 사용 조건 |
|------|------|------|------|----------|
| 키워드 검색 | [방식] | [장점] | [단점] | [조건] |
| 의미 검색 | [방식] | [장점] | [단점] | [조건] |
| 하이브리드 | [방식] | [장점] | [단점] | [조건] |

### 6.2 Agent의 전략 선택/변경 구조
1. 초기 전략: [기본 전략]
2. 결과 평가: [평가 방법]
3. 전략 변경 조건: [조건]
4. 변경 후 전략: [대안 전략]

### 6.3 편향/노이즈 감지 방식
- 감지 방법: [방법]
- 대응: [대응 방안]

---

## 7. LangGraph 오케스트레이션 구조

### 7.1 주요 노드(Node) 정의
| 노드명 | 역할 | 입력 | 출력 | 상태 업데이트 |
|--------|------|------|------|--------------|
| [노드1] | [역할] | [입력] | [출력] | [상태 변경] |
| [노드2] | [역할] | [입력] | [출력] | [상태 변경] |

### 7.2 조건부 엣지(Conditional Edge)
| 출발 노드 | 조건 | 도착 노드 |
|----------|------|----------|
| [노드A] | state.충분 == True | [노드B] |
| [노드A] | state.충분 == False | [노드C] (재수집) |
| [노드C] | state.시도 < 3 | [노드A] (루프) |
| [노드C] | state.시도 >= 3 | [종료] |

### 7.3 순환 구조 및 탈출 조건
- **루프 1**: [노드A] → [노드B] → [노드A]
  - 탈출 조건: [조건]
  - 최대 반복: N회

### 7.4 그래프 다이어그램
```
START → receiveInput → analyzeQuery
                           ↓
          ┌──────────── (충분?) ──────────┐
          ↓ No                        Yes ↓
    collectMore ← (시도<3?)        executeAction
          ↓ Yes                          ↓
    analyzeQuery                      END
```

---

## 8. 개인화 및 제약 조건

### 8.1 사용자 특성 반영
| 사용자 특성 | 반영 방식 | 예시 |
|------------|----------|------|
| [특성1] | [행동 선택 변경] | [예시] |
| [특성2] | [도구 우선순위 변경] | [예시] |

### 8.2 제약 조건
- 비용: 최대 [금액]/건
- 시간: 최대 [시간]초
- 정확도: 최소 [점수]

---

## 9. 실패 시나리오 및 안전장치

### 9.1 잘못된 판단 가능 지점
| 지점 | 원인 | 영향 | 감지 방법 | 대응 |
|------|------|------|----------|------|
| [지점1] | [원인] | [영향] | [방법] | [대응] |

### 9.2 안전장치
- **재시도 한계**: 최대 N회
- **비용 상한**: [금액]/건, 초과 시 중단
- **타임아웃**: [시간]초, 초과 시 보류
- **사람 개입**: [조건]

### 9.3 불확실성 처리
- 불확실성 명시 조건: [조건]
- 보류 조건: [조건]
- 경고 메시지: [메시지]

---

## 10. Agent다움 검증

### 10.1 Agent 검증 체크리스트
- [x] 자율 판단: 충분성/신뢰도를 스스로 평가
- [x] 도구 선택: 상황별 도구/전략 선택
- [x] 반복 개선: 실패 시 재시도/전략 변경
- [x] 상태 누적: 과거 행동/결과 기억 및 활용
- [x] 순환 구조: 조건 분기와 루프 존재
- [x] 퇴화 방지: 자동화 퇴화 방지 장치
- [x] 불확실성 처리: 불확실성 명시/보류 가능
- [x] 안전장치: 비용/시간 폭주 방지

### 10.2 Agent가 아니게 되는 순간
- [순간1]: [설명 및 방지 방법]
- [순간2]: [설명 및 방지 방법]

### 10.3 퇴화 방지 설계적 장치
- [장치1]: [설명]
- [장치2]: [설명]

---

## 11. 다관점 평가

### 11.1 기획 관점
**강점**: [3개 이상]
**약점**: [3개 이상]
**개선 방안**: [구체적]

### 11.2 기술 관점
**강점**: [3개 이상]
**약점**: [3개 이상]
**개선 방안**: [구체적]

### 11.3 비즈니스 관점
**강점**: [3개 이상]
**약점**: [3개 이상]
**개선 방안**: [구체적]

### 11.4 사용자 관점
**강점**: [3개 이상]
**약점**: [3개 이상]
**개선 방안**: [구체적]

### 11.5 Agent다움 관점
**강점**:
- 자율성: [평가]
- 적응성: [평가]
- 판단력: [평가]

**약점**:
- 퇴화 리스크: [평가]
- 비용 관리: [평가]
- 복잡도: [평가]

**개선 방안**: [구체적]

---

## 12. 실행 계획 및 검증

### 12.1 단계별 일정
| 단계 | 마일스톤 | 기간 | 핵심 의사결정 | 검증 방법 |
|------|----------|------|-------------|----------|
| 1차 | [마일스톤] | [기간] | [의사결정1 구현] | [판단 정확도 측정] |
| 2차 | [마일스톤] | [기간] | [의사결정2 구현] | [비용 효율 측정] |

### 12.2 우선순위
- **1차 (MVP)**: [의사결정1] + [도구A, B] + [안전장치]
- **2차**: [의사결정2] + [도구C] + [개인화]
- **3차**: [추가 전략] + [고도화]

### 12.3 검증 방법
- 판단 정확도: [측정 방법], 목표 [값]
- 재시도율: [측정 방법], 목표 [값]
- 비용 효율: [측정 방법], 목표 [값]
- 사용자 만족도: [측정 방법], 목표 [값]

### 12.4 리소스 배분
- Agent 개발: [인력/시간]
- 도구 통합: [인력/시간]
- 모니터링: [인력/시간]

---

## 13. 평가 점수

| 영역 | 항목 | 점수 | 비고 |
|------|------|------|------|
| 기획 | 문제/Agent 필요성 명확성 | /5 | |
| 기획 | 의사결정 정의 구체성 | /5 | |
| 기획 | 판단 로직 명확성 | /5 | |
| 기획 | 실행 가능성 | /5 | |
| 기술 | Agent 프레임워크 적합성 | /5 | |
| 기술 | 오케스트레이션 설계 건전성 | /5 | |
| 기술 | 도구 설계 완성도 | /5 | |
| 기술 | 안전장치 완비 | /5 | |
| 비즈니스 | 차별화 (vs 자동화) | /5 | |
| 비즈니스 | 비용 효율성 | /5 | |
| 비즈니스 | 확장 가능성 | /5 | |
| 비즈니스 | 실행 용이성 | /5 | |
| 사용자 | 가치 전달 명확성 | /5 | |
| 사용자 | 신뢰성 | /5 | |
| 사용자 | 투명성 (판단 근거) | /5 | |
| 사용자 | 만족도 기대치 | /5 | |
| **Agent다움** | **자율 판단 능력** | **/5** | |
| **Agent다움** | **반복 개선 구조** | **/5** | |
| **Agent다움** | **퇴화 방지 장치** | **/5** | |
| **Agent다움** | **실패 대응 전략** | **/5** | |
| **총점** | | **/100** | |

### 판정
- [ ] 80점 이상: 즉시 실행 권장 (Agent 완성도 높음)
- [ ] 65-79점: 보완 후 실행 (일부 강화 필요)
- [ ] 50-64점: 상당한 보완 필요 (퇴화 리스크)
- [ ] 50점 미만: 재기획 권장 (Agent 아님)

---

## 부록

### A. Agent 용어 정의
- **State**: Agent가 유지하는 내부 상태
- **Conditional Edge**: 상태에 따른 조건 분기
- **Tool**: Agent가 사용하는 외부 도구
- **Loop**: 불충분 시 재수행 구조

### B. 기술 참고
- LangGraph 문서: [링크]
- Agent 패턴: [링크]

### C. 변경 이력
| 날짜 | 버전 | 변경 내용 | 작성자 |
|------|------|-----------|--------|
| YYYY-MM-DD | 1.0 | Agent 기획 초안 | [작성자] |
```

### 문서 생성 프로세스
1. 1-6단계 문답 내용 수집 및 Agent 특성 확인
2. Agent Service 전용 템플릿 사용
3. 각 섹션별 내용 작성
   - 대괄호 [...] 부분을 실제 내용으로 치환
   - 판단 기준표, 상태 정의, 노드 구조 등 표 형식 활용
   - 플로우 다이어그램 포함 (텍스트 형식)
   - 불릿 포인트로 명확하게 표현
4. **Agent 검증 체크리스트 8개 항목 확인**
5. 평가 점수 산정 및 판정 (/100점)
6. 문서 파일 생성 및 저장
7. 사용자에게 완료 안내 (점수 및 판정 포함)

### 문서 생성 시 주의사항
- **Agent 필요성 명시**: "왜 Agent여야 하는가" 섹션 필수
- **판단 기준 정량화**: 모든 판단에 구체적 기준
- **순환 구조 명시**: 플로우 다이어그램으로 시각화
- **퇴화 방지 강조**: 자동화로 퇴화하는 시나리오 명시
- 구어체를 문어체로 변환
- 중복 내용 제거
- 모호한 표현 구체화 ("판단한다" → "N개 이상일 때 충분 판단")
- 정량적 지표 필수 (재시도 횟수, 비용, 시간)
- 실행 가능한 수준으로 작성 (LangGraph 노드 구현 가능)
- 부록 A(Agent 용어)는 필수 포함

## 평가 기준

### 기획 완성도 (20점)
- 문제/Agent 필요성 명확성: 5점
- 의사결정 정의 구체성: 5점
- 판단 로직 명확성: 5점
- 실행 가능성: 5점

### 기술 타당성 (20점)
- Agent 프레임워크 적합성: 5점
- 오케스트레이션 설계 건전성: 5점
- 도구 설계 완성도: 5점
- 안전장치 완비: 5점

### 비즈니스 가치 (20점)
- 차별화 (vs 자동화/챗봇): 5점
- 비용 효율성: 5점
- 확장 가능성: 5점
- 실행 용이성: 5점

### 사용자 경험 (20점)
- 가치 전달 명확성: 5점
- 신뢰성 (판단 정확도): 5점
- 투명성 (판단 근거 제공): 5점
- 만족도 기대치: 5점

### Agent다움 (20점) ⭐
- 자율 판단 능력: 5점
- 반복 개선 구조: 5점
- 퇴화 방지 장치: 5점
- 실패 대응 전략: 5점

**총점: 100점**
- 80점 이상: 즉시 실행 권장 (Agent 완성도 높음)
- 65-79점: 보완 후 실행 (일부 강화 필요)
- 50-64점: 상당한 보완 필요 (퇴화 리스크 존재)
- 50점 미만: 재기획 권장 (Agent가 아님)

## Agent Service 기획 대화 예시

```
=== 1단계: 핵심 파악 및 Agent 필요성 검증 ===
[AI] 해결하려는 문제는 무엇인가요?
[사용자] 응답
[AI] 왜 이 문제는 단순 자동화로 해결할 수 없나요?
[사용자] 응답
[AI] 어떤 부분에서 AI의 자율 판단이 필요한가요?
[사용자] 응답
[AI] 정보가 불충분하거나 불확실할 때 어떻게 대응해야 하나요?
[사용자] 응답

=== 2단계: Agent 핵심 능력 및 MVP 정의 ===
[AI] AI가 스스로 판단해야 하는 핵심 의사결정 3가지는?
[사용자] 응답
[AI] 각 판단에서 '충분하다/부족하다/신뢰 불가'를 어떻게 구분하나요?
[사용자] 응답
[AI] 도구가 실패하면 어떤 대안이 있나요?
[사용자] 응답

=== 3단계: Agent 상태 및 판단 로직 설계 ===
[AI] Agent가 내부적으로 유지해야 하는 핵심 상태는?
[사용자] 응답
[AI] 이 상태가 다음 판단에 어떻게 영향을 주나요?
[사용자] 응답
[AI] '충분하다'의 정량적 기준은? (예: 결과 3개 이상, 신뢰도 0.8 이상)
[사용자] 응답
[AI] 어느 지점에서 Agent가 이전 단계로 돌아가나요?
[사용자] 응답

=== 4단계: Agent 오케스트레이션 및 도구 설계 ===
[AI] LangGraph 또는 다른 Agent 프레임워크를 사용하나요?
[사용자] 응답
[AI] Agent가 사용할 도구 목록은?
[사용자] 응답
[AI] 각 도구를 선택하는 조건은?
[사용자] 응답

=== 5단계: Agent 실패 시나리오 및 안전장치 ===
[AI] 잘못된 판단이 발생할 수 있는 지점은?
[사용자] 응답
[AI] 최대 재시도 횟수와 비용 상한선은?
[사용자] 응답
[AI] 이 서비스가 단순 자동화로 퇴화하는 순간은 언제인가요?
[사용자] 응답
[AI] 퇴화 방지를 위한 설계적 장치는?
[사용자] 응답

=== 6단계: 개인화 및 추가 의견 수렴 ===
[AI] 사용자 성향/환경이 Agent 판단에 어떻게 반영되나요?
[사용자] 응답
[AI] 개인화가 '문장 톤'이 아닌 '행동 선택'에 영향을 주나요?
[사용자] 응답
[AI] Agent다움을 유지하기 위해 지켜야 할 원칙은?
[사용자] 응답

=== 7단계: 종합 정리 및 Agent 검증 ===
[AI] 종합 정리 및 Agent 검증을 시작하겠습니다.
(5개 관점 평가 수행)
(Agent 검증 체크리스트 8개 항목 확인)
(평가 점수 산정: /100점)

[AI] Agent Service 기획 문서를 생성하겠습니다.
(문서 생성 완료)
[AI] 기획 문서가 생성되었습니다: planning_agent_[프로젝트명]_[날짜].md
[AI] 평가 점수: [점수]/100점 - [판정]
```

## Agent Service 기획 프로세스 최적화 팁

### 시간 관리
- 전체 90분 이내 (Agent 복잡도 고려)
- 단계별 시간 엄수
- 상태/판단 로직 설계에 충분한 시간 할애
- MVP 의사결정 1-2개로 제한

### Agent 특화 질문 전략
- **필수 질문**: Agent 필요성, 판단 기준, 상태 설계, 순환 구조
- **선형 사고 경계**: "그 다음은?"보다 "실패하면?"에 집중
- **퇴화 리스크 체크**: 각 단계에서 "이게 고정 룰이 되면?"질문
- **구체성 확보**: "판단한다" → "무엇을 기준으로 어떻게 판단하나?"

### Agent 검증 체크
- Agent 검증 체크리스트 8개 항목 필수 통과
- 하나라도 미통과 시 해당 영역 보강 질문
- "이게 단순 자동화와 뭐가 다른가?" 반복 확인

### 평가 심도
- 5개 관점 (기획/기술/비즈니스/사용자/**Agent다움**) 각 3개 이상
- **Agent다움 관점**에 최소 20% 시간 할애
- 정량적 기준 필수: 재시도 횟수, 비용 상한, 타임아웃
- 퇴화 시나리오 구체화

### 문서 생성
- Agent 전용 템플릿 사용
- 판단 기준표, 상태 정의, 노드 구조 등 표 형식 활용
- 플로우 다이어그램 포함
- 모든 대괄호 [...] 치환
- 구어체 → 문어체 변환
- 평가 점수 산정 (/100점)

## 응용: Agent Service 유형별 변형

### 정보 검색 Agent
- 핵심 판단: 정보 충분성, 신뢰도, 관련성
- 주요 도구: 검색 API, 벡터 DB, 지식 그래프
- 순환 구조: 불충분 → 쿼리 재구성 → 재검색
- 퇴화 리스크: 단순 키워드 검색으로 고정

### 의사결정 지원 Agent
- 핵심 판단: 옵션 평가, 트레이드오프 분석, 불확실성 평가
- 주요 도구: 시뮬레이션, 규칙 엔진, 외부 데이터
- 순환 구조: 정보 부족 → 추가 분석 → 재평가
- 퇴화 리스크: 고정 가중치 점수 계산으로 퇴화

### 작업 자동화 Agent
- 핵심 판단: 작업 순서 선택, 실패 처리, 재시도 전략
- 주요 도구: API 호출, 데이터 처리, 알림
- 순환 구조: 실패 → 대안 선택 → 재시도
- 퇴화 리스크: 고정 시퀀스 실행으로 퇴화

### 개인화 추천 Agent
- 핵심 판단: 사용자 의도 파악, 맥락 이해, 추천 적합성
- 주요 도구: 추천 모델, 사용자 프로필, 피드백 수집
- 순환 구조: 불만족 감지 → 전략 변경 → 재추천
- 퇴화 리스크: 단순 협업 필터링으로 퇴화

### 대화형 Agent
- 핵심 판단: 의도 명확성, 정보 충분성, 응답 적절성
- 주요 도구: LLM, 지식 베이스, 외부 API
- 순환 구조: 불명확 → 재질문 → 명확화
- 퇴화 리스크: 단순 FAQ 봇으로 퇴화

## Agent Service 성공 원칙

### Agent여야만 하는 이유가 명확해야 함
- 고정 룰로 해결 불가능
- 불확실성/가변성 존재
- 맥락 의존적 판단 필요

### 상태가 행동을 변경해야 함
- 과거 시도가 다음 전략에 영향
- 누적 정보가 판단에 반영
- 학습/개선 구조 존재

### 실패가 재시도로 이어져야 함
- 실패 = 종료 (X)
- 실패 = 대안 탐색 (O)
- 안전장치로 무한 루프 방지

### 투명성이 신뢰를 만듦
- 판단 근거 제공
- 불확실성 명시
- 중간 과정 공개

### 비용과 가치의 균형
- 단순 자동화가 더 효율적이면 자동화
- Agent 복잡도가 가치를 정당화해야 함
- 점진적 고도화 전략

