# 맛집 정보 수집 및 분석 AI Agent Service 기획서

**작성일**: 2026-01-07
**작성자**: AI Agent + 사용자
**버전**: 0.3.1 (3단계 개선 완료)
**문서 유형**: AI Agent Service 기획

> ⚠️ **중요**: 이 문서는 단순 챗봇/자동화가 아닌, 자율 판단·도구 선택·반복 개선이 가능한 **AI Agent Service** 기획서입니다.

---

## 진행 상태
- [x] 1단계: 핵심 파악 및 Agent 필요성 검증
- [x] 2단계: Agent 핵심 능력 및 MVP 정의
- [x] 3단계: Agent 상태 및 판단 로직 설계
- [ ] 4단계: Agent 오케스트레이션 및 도구 설계
- [ ] 5단계: Agent 실패 시나리오 및 안전장치
- [ ] 6단계: 개인화 및 추가 의견 수렴
- [ ] 7단계: 종합 정리 및 Agent 검증

---

## 1. 서비스 개요

### 1.1 문제 정의

#### 해결하려는 문제
음식점/장소 검색 시 여러 장소를 비교하기 위해 대량의 블로그 정보를 수집하고 분석해야 하는 문제

**구체적 상황**:
- **규모**: 5개 이상의 장소를 비교하기 위해 장소당 5개 이상의 블로그 확인 (총 25개 이상의 정보원)
- **소요 시간**: 1시간 이상
- **주요 어려움**:
  - 핵심 정보 추출의 어려움
  - 장단점 정리의 복잡성
  - 체험단/보상 블로그 구분
  - 블로그마다 다른 의견 종합

**판단 프로세스**:
- 맛, 가격, 접근성, 꿀팁을 기준으로 판단
- 부정적 리뷰도 이유를 확인하여 재평가 필요
- 블로그 내용의 객관성/주관성 구분 필요

#### 타겟 사용자
**1순위 타겟**: 맛집 탐방을 좋아하는 사람

**사용자 특성**:
- 연령대: 20-30대 직장인
- 탐방 빈도: 주 1회 이상
- 인원: 혼자 또는 4인
- 예산: 한 끼당 3-4만원
- SNS: 공유하는 편
- 특징: 즉발성이 아니며, 결과 활용률이 높음

**핵심 페인포인트**: 
- 정보 수집 및 분석에 시간이 너무 많이 걸림 (1시간 이상)

**선정 이유**:
- 즉발성이 아니어서 AI Agent가 깊이 있는 분석을 수행할 가치가 있음
- 결과 활용률이 높아 서비스의 효용이 큼

#### 현재 해결 방법
**사용 도구**: 네이버 지도 + 네이버 블로그

**현재 프로세스**:
1. 네이버 지도에서 검색 (예: "강남역 파스타")
2. 평점/리뷰 보고 5개 장소 선정
3. 각 장소 이름으로 블로그 검색
4. **블로그 5개씩 읽으며 엑셀/카톡에 메모** ← 가장 힘듦
5. **장단점 + 인기 메뉴 정리** ← 가장 힘듦
6. 동료들과 공유하여 의사결정

**자동화 우선순위**:
1. **정보 수집 자동화** (블로그 수집, 체험단 필터링)
2. **정보 분석 자동화** (종합 & 장단점 정리, 모순 판단)
3. **비교 자동화** (5개 장소 비교표, 추천)

### 1.2 Agent 필요성 검증

#### 왜 Agent여야만 하는가?

**단순 자동화로 불가능한 이유**:
1. **광고/체험단 구분**: 키워드만으로는 한계, 맥락 이해 필요
   - 판단 신호: "이 글은 체험단으로 작성되었습니다" 문구/이미지
   
2. **내용 정리/요약**: 사람의 판단 필요
   - 블로그 품질 판단 (사진 많음, 구체적 가격, 단점 언급, 최근 방문)
   - 객관적 정보 vs 주관적 의견 구분
   - 정보 모순 해결

3. **정보 충분성 판단**: 상황에 따라 달라짐
   - 고품질 블로그 3개가 충분한가?
   - 모두 광고면 어떻게?
   - 10개를 봐도 부족하면?

#### AI 자율 판단이 필요한 영역

**핵심 AI 판단 (6가지)**:

**1. 정보 충분성 판단**
- "현재 수집된 정보가 충분한가?"
- "더 많은 블로그를 찾아야 하나?"
- 기준:
  - 필수 항목 (100%): 주소, 메뉴
  - 비교 항목 (2개): 맛, 접근성
  - 권장 항목 (1개 이상): 웨이팅, 주차, 영업시간 중 최소 1개

**2. 객관/주관 구분**
- "이 정보가 객관적인가 주관적인가?"
- 객관적: 가격, 웨이팅, 주차, 메뉴명, 영업시간 (팩트)
- 주관적: "맛있어요", "분위기 좋아요", "양이 많아요" (의견)
- 주관적 정보 중 개인 기준에 따라 달라지는 내용은 제외

**3. 모순 해결**
- "서로 다른 정보를 어떻게 처리할 것인가?"
- 객관적 정보 모순 (예: 가격 차이):
  - 최신 데이터 사용 (날짜 기준)
  - 사실성에 대한 안내 코멘트 추가
- 주관적 의견 모순 (예: 양 평가):
  - 개인 주관에 따라 달라지는 내용은 제외

**4. 장소 특색 판단**
- "이 장소의 특색은 무엇인가?"
- 특색 요소:
  - 특별한 메뉴 (시그니처 메뉴)
  - 가성비
  - 공통 언급 패턴 ("이 메뉴 먹으러 왔어요" 등)
- 여러 블로그에서 공통으로 언급되는 포인트를 특색으로 판단

**5. 장소 간 비교 기준 선택**
- "어떤 기준으로 비교할 것인가?"
- 접근 방식:
  - 고정된 기준 (맛/가격/접근성/특색 등)
  - 항목별 점수 측정
  - 종합 평가 데이터 제공
  - 최종 선택은 사용자가 직접 (AI가 1순위 강요 안 함)

**6. 예외 상황 처리**
- "문제 발생 시 어떻게 대응할 것인가?"

**상황 1 - 모든 블로그가 광고/체험단**:
- 객관적 정보만 추출 시도
- 동시에 더 많은 블로그 검색

**상황 2 - 정보가 여전히 부족**:
- 탐색 종료 (무한 검색 방지)
- 모아진 데이터로만 종합
- "정보가 제한적일 수 있음" 암묵적 반영

**탐색 한계**:
- 초기 설정: 장소당 블로그 **5개**
- 검증 지표: 속도, 토큰 소비량, 수집되는 정보량
- 데이터 기반으로 증량 판단

#### 불확실성 처리 방식

**정보 불충분 시**:
- 추가 검색 하지 않음
- 장소 제외 하지 않음
- "정보 부족" 명시적 표시 안 함
- → **수집된 데이터만으로 평가 작성**

**이유**:
- 비용/시간 통제
- 완벽주의 배제
- "있는 정보로 최선" 철학

#### 사용자별 차별화

**MVP**: 개인화 제외
- 모든 사용자에게 동일한 결과 제공
- 향후 고려사항:
  - 사용자별 가격 민감도
  - 선호 분위기 (데이트용, 혼밥용)
  - 검색 이력 기반 맞춤

### 1.3 기존 솔루션과의 차이

| 구분 | 기존 방식 (수동) | 본 Agent Service |
|------|----------------|------------------|
| 정보 수집 | 25개+ 블로그 수동 탐색 | 자동 수집 및 필터링 |
| 광고 구분 | 사람이 직접 확인 | AI가 체험단 문구/이미지 감지 |
| 객관/주관 구분 | 사람이 직접 판단 | AI가 자동 분류 |
| 정보 종합 | 엑셀/카톡 수동 메모 | AI가 자동 분석 및 정리 |
| 모순 처리 | 사람이 직접 판단 | AI가 최신 데이터 우선, 주관 제외 |
| 특색 파악 | 사람이 패턴 파악 | AI가 공통 언급 자동 추출 |
| 비교 | 수동 정리 | 항목별 점수화 자동 비교 |
| 소요 시간 | 1시간 이상 | [측정 예정] |
| 결과 형태 | 엑셀/카톡 메모 | 구조화된 비교 데이터 |

### 1.4 핵심 가치

1. **시간 절약**: 1시간 이상 → [목표: 10분 이내]
2. **판단 품질**: 사람 수준의 객관/주관 구분, 모순 해결
3. **일관성**: 항상 같은 기준으로 평가
4. **공유 용이**: 동료와 공유 가능한 구조화된 데이터
5. **자율성**: 정보 충분성을 스스로 판단하여 탐색 종료

---

## 2. MVP 범위 및 제약사항

### 2.1 MVP에 포함
- 블로그 기반 정보 수집 (장소당 최대 5개)
- 체험단/광고 필터링
- 객관/주관 정보 구분
- 장소 특색 자동 파악
- 5개 장소 비교 (맛/접근성 중심)
- 동일한 결과 제공 (개인화 없음)

### 2.2 MVP에서 제외
- **가격 정보**: OCR 필요, 화질/화각 문제로 난이도 높음
  - 없으면 없는 대로 진행 (명시적 표시 안 함)
- **개인화**: 사용자별 맞춤 결과 (향후 적용)
- **다른 소스**: 인스타, 유튜브 등 (블로그만 사용)
- **장소 추천 순위**: 비교 데이터만 제공, 최종 선택은 사용자

### 2.3 주요 제약사항
- 블로그 최대 5개 탐색 (비용/시간 통제)
- 가격 정보 누락 가능
- 네이버 블로그만 지원
- 정보 부족 시 추가 검색 하지 않음

---

## 2. AI Agent 역할 정의

### 2.1 핵심 의사결정 목록

1단계에서 도출된 6가지 AI 판단 중 **MVP에 포함할 핵심 의사결정 3가지**:

| 순위 | 의사결정 | 설명 | MVP 포함 |
|------|---------|------|----------|
| 1 | 정보 충분성 판단 | 수집된 정보가 충분한지 평가 | ✅ |
| 2 | 장소 특색 판단 | 이 장소만의 특색 파악 | ✅ |
| 3 | 비교 기준 선택 (점수화) | 항목별 점수 산정 및 종합 평가 | ✅ |
| 4 | 객관/주관 구분 | 객관적 정보와 주관적 의견 분류 | ⏸️ 향후 |
| 5 | 모순 해결 | 서로 다른 정보 처리 | ⏸️ 향후 |
| 6 | 예외 상황 처리 | 문제 발생 시 대응 | ⏸️ 향후 |

**선택 이유**: "정보 수집 → 특색 파악 → 비교"의 핵심 플로우만 MVP에 포함

### 2.2 의사결정별 판단 기준

#### 의사결정 1: 정보 충분성 판단

**전체 항목**:
- 필수 항목: 주소, 메뉴 (2개)
- 비교 항목: 맛, 접근성 (2개)
- 권장 항목: 웨이팅, 주차, 영업시간 (3개 중 택)

**판단 기준표**:

| 판단 결과 | 조건 | 후속 행동 |
|----------|------|----------|
| **충분** | 전체 항목 3개 이상 수집됨 | 다음 단계 진행 (특색 판단) |
| **부족** | 전체 항목 3개 미만 | 현재 데이터로 진행 (탐색 종료) |

**예시**:
- 주소 + 메뉴 + 맛 = 3개 → **충분** ✅
- 주소 + 접근성 + 주차 = 3개 → **충분** ✅
- 주소 + 메뉴 = 2개 → **부족**, 현재 데이터로 진행

**특징**:
- 유연한 기준 (항목 조합 자유)
- "신뢰불가" 상태 제거 (모순은 시간/관점 차이로 해석)
- 부족해도 진행 (완벽주의 배제)

#### 의사결정 2: 장소 특색 판단

**특색 요소**:
- 특별한 메뉴 (시그니처 메뉴)
- 가성비
- 공통 언급 패턴

**판단 기준표**:

| 판단 결과 | 조건 | 출력 |
|----------|------|------|
| **충분** | 언급 비중이 가장 높은 항목 존재 | 해당 항목을 특색으로 표시 |
| **동률** | 2개 이상의 항목이 같은 비중 | 모두 특색으로 표시 |
| **부족** | 언급이 없거나 모두 1회씩만 | "특색 정보 없음" |

**예시**:
- 크림파스타 3회, 토마토파스타 2회 → **"크림파스타"**
- 크림파스타 3회, 토마토파스타 3회 → **"크림파스타, 토마토파스타"** (둘 다)
- 각 메뉴 1회씩 → **특색 정보 없음**

#### 의사결정 3: 비교 기준 선택 (점수화)

**평가 항목 (5개)**:

| 항목 | 가중치 | 최대 기여도 |
|------|--------|-------------|
| 맛 | 40% | 400점 |
| 가격 | 20% | 200점 |
| 서비스/친절도 | 20% | 200점 |
| 양/가성비 | 10% | 100점 |
| 웨이팅 | 10% | 100점 |
| **합계** | **100%** | **1000점** |

**변경 사항**:
- "접근성" 제거 (네이버 지도에서 확인 가능, 블로그에서 잘 다루지 않음)
- "서비스/친절도", "양/가성비" 추가

**각 항목 점수 산정 방식**:

| 요소 | 점수 |
|------|------|
| 기본 점수 | 500점 |
| 긍정 언급 1회 | +100점 |
| 부정 언급 1회 (확실한 단어만) | -100점 |
| 최소 점수 | 0점 |
| 최대 점수 | 1000점 |

**긍정 언급 예시**:
- 맛: "맛있다", "맛집", "최고" 등
- 가격: "저렴하다", "가성비", "합리적" 등
- 서비스: "친절하다", "서비스 좋다" 등
- 양: "푸짐하다", "양 많다" 등
- 웨이팅: "웨이팅 없다", "바로 입장" 등

**부정 언급 예시** (확실한 단어만):
- 맛: "맛없다", "별로", "실망" 등
- 가격: "비싸다", "가격이 부담" 등
- 서비스: "불친절하다", "서비스 나쁘다" 등
- 양: "적다", "부족하다" 등
- 웨이팅: "웨이팅 길다", "1시간 대기" 등

**종합 점수 계산**:
```
종합 점수 = (맛 점수 × 40%) + (가격 점수 × 20%) + (서비스 점수 × 20%) + (양 점수 × 10%) + (웨이팅 점수 × 10%)
```

**예시**:
- 맛: 1000점 × 40% = 400점
- 가격: 600점 × 20% = 120점
- 서비스: 800점 × 20% = 160점
- 양: 500점 × 10% = 50점
- 웨이팅: 400점 × 10% = 40점
→ **종합: 770점/1000점**

**특징**:
- 게임 랭킹처럼 1000점 만점 (심리적 효과)
- 가중치로 중요도 차등 반영
- 일률적 가감점 (단순성)
- 항목별 독립 점수 → 가중치 합산

### 2.3 AI가 책임지는 판단 영역

**AI가 자율적으로 결정**:
1. 블로그 N개를 봤을 때 정보가 충분한지 (3개 항목 이상?)
2. 어떤 메뉴/요소가 이 장소의 특색인지 (언급 비중 분석)
3. 각 항목(맛/가격/서비스/양/웨이팅)의 점수 (긍정/부정 언급 카운팅)
4. 5개 장소의 종합 점수 계산

**사람(사용자)에게 위임**:
1. 5개 장소 중 최종 선택
2. 가중치 조정 (향후 개인화 시)
3. 추가 장소 검색 여부

### 2.4 실패 시 대응 방식

| 상황 | AI 판단 | 대응 방식 |
|------|---------|----------|
| 정보 3개 미만 | 부족 | 현재 데이터로 진행, 점수는 낮게 산정됨 |
| 특색 파악 불가 | 부족 | "특색 정보 없음" 표시 |
| 블로그 5개 모두 광고 | (판단 없음) | 향후 구현 (2단계 제외) |
| 모순된 정보 | (판단 없음) | 향후 구현 (2단계 제외) |

**특징**:
- 재시도 없음 (비용/시간 통제)
- 경로 변경 없음 (단순성)
- 보류/실패 없음 (항상 결과 제공)
- "있는 정보로 최선" 철학

---

## 3. 성공 지표

### 3.1 Agent 판단 정확도

**측정 방법**: 사람의 판단과 비교

| 항목 | 측정 방법 | 목표 |
|------|----------|------|
| 정보 충분성 판단 | 사람이 평가한 "충분" vs AI 판단 일치율 | 80% 이상 |
| 특색 파악 정확도 | 사람이 선택한 특색 vs AI 판단 일치율 | 70% 이상 |
| 점수 타당성 | 사람의 종합 평가와 AI 점수 상관관계 | 상관계수 0.7 이상 |

### 3.2 서비스 효율성

| 항목 | 현재 (수동) | 목표 (AI Agent) |
|------|------------|----------------|
| 소요 시간 | 1시간 이상 | 10분 이내 |
| 정보 수집 | 25개 블로그 수동 | 25개 블로그 자동 |
| 비교 작성 | 수동 메모 | 자동 생성 |

### 3.3 사용자 만족도

| 항목 | 측정 방법 | 목표 |
|------|----------|------|
| 결과 만족도 | 5점 척도 설문 | 평균 4점 이상 |
| 재사용 의향 | 5점 척도 설문 | 평균 4점 이상 |
| 시간 절감 체감 | 5점 척도 설문 | 평균 4.5점 이상 |

### 3.4 비용 효율성

| 항목 | 목표 |
|------|------|
| 장소당 처리 비용 | 500원 이하 (LLM API 비용) |
| 토큰 사용량 | 장소당 50,000 토큰 이하 |
| 처리 시간 | 장소당 1분 이내 |

### 3.5 검증 기간

- **1차 검증**: 2주 (소규모 테스트, 10명)
- **2차 검증**: 4주 (확장 테스트, 50명)
- **지표 수집**: 매주 리뷰
- **개선 반영**: 격주 업데이트

---

## 3. 상태(State) 중심 설계

### 3.1 핵심 상태 정의

Agent가 실행 중에 유지하는 내부 상태 구조입니다.

#### 전체 상태 구조

```python
state = {
    "all_places": [
        {
            "name": "장소명",
            "naver_map_url": "네이버 지도 URL",
            "address": "주소",
            "collected_blogs_count": 5,
            "max_blogs_target": 5,  # 동적 조정 가능 (3-10개)
            "collected_info": [
                {
                    "blog_id": 1,
                    "blog_url": "블로그 URL",
                    "post_date": "2025-12-15",
                    "raw_text": "분석에 결정적인 부분만 추출된 텍스트",
                    "주소": "서울 강남구 역삼동 123",
                    "메뉴": ["크림파스타", "샐러드"],
                    "맛": "긍정",  # 긍정/부정/None
                    "가격": "긍정",
                    "서비스": None,
                    "양": None,
                    "웨이팅": "부정"
                }
                # ... 최대 5개 블로그
            ],
            "info_count": 4,  # 수집된 항목 개수
            "is_sufficient": True,  # 3개 이상이면 True
            "relevance_status": "pass",  # pass/fail
            "relevance_reason": "",  # 미달 시 이유
            "scores": {
                "맛": 700,
                "가격": 600,
                "서비스": 500,
                "양": 500,
                "웨이팅": 400
            },
            "total_score": 570,
            "specialty": "크림파스타"
        }
        # ... 최대 5개 장소
    ],
    "current_place_index": 0,
    "total_places": 5,
    "start_time": "2026-01-07 14:00:00",
    "elapsed_time": 120,  # 초
    "user_query": "강남역 파스타 맛집",
    "location_keyword": "강남역",
    "food_keyword": "파스타",
    "search_query_optimized": "강남역 파스타",
    "retry_count": 0  # 재검색 횟수
}
```

#### 상태 필드 설명

| 필드 | 타입 | 초기값 | 역할 |
|------|------|--------|------|
| `all_places` | List | [] | 모든 장소 정보 |
| `collected_blogs_count` | int | 0 | 분석 완료한 블로그 수 |
| `max_blogs_target` | int | 5 | 목표 블로그 수 (동적 조정: 3-10개) |
| `collected_info` | List | [] | 블로그별 분석 결과 |
| `raw_text` | str | "" | 분석에 결정적인 원문 부분 |
| `info_count` | int | 0 | 수집된 항목 개수 (판단 및 행동 영향) |
| `is_sufficient` | bool | False | 정보 충분 여부 (판단 및 행동 영향) |
| `relevance_status` | str | "" | 연관성 평가 결과 |
| `relevance_reason` | str | "" | 미달 시 이유 |
| `scores` | dict | {항목: 500} | 항목별 점수 |
| `total_score` | int | 500 | 가중치 합산 점수 |
| `specialty` | str | "" | 특색 메뉴/요소 |
| `retry_count` | int | 0 | 재검색 횟수 |

### 3.2 상태가 다음 행동에 미치는 영향

Agent의 행동을 결정하는 핵심 상태와 그 영향:

#### 1. `info_count` (수집된 정보 항목 개수) - 핵심 판단 기준

**블로그 3개 분석 후 중간 평가 시점**:

| info_count | 판단 | Agent 행동 |
|-----------|------|----------|
| **≥ 3** | 충분 | `is_sufficient = True` → **조기 종료 가능** (다음 장소로) |
| **< 2** | 매우 부족 | `is_sufficient = False` → **목표 확장** (`max_blogs_target = 7`) |
| **2** | 부족 | `is_sufficient = False` → 기본 목표 유지 (`max_blogs_target = 5`) |

**의사 코드**:
```python
# 블로그 3개 분석 완료 시점
if collected_blogs_count == 3:
    if info_count >= 3:
        # 정보 충분 → 조기 종료
        return  # 다음 장소로 이동
    elif info_count < 2:
        # 정보 매우 부족 → 목표 확장
        max_blogs_target = 7
    # info_count == 2: 기본 목표(5개) 유지
```

**특징**: 
- Agent가 정보 충분성 판단 결과에 따라 **실제 행동 변경** ✅
- 비용 최적화 (불필요한 수집 감소)
- 정보 품질 향상 (부족 시 추가 수집)

#### 2. `collected_blogs_count` & `max_blogs_target` (블로그 수집 완료 여부)

| 조건 | Agent 행동 |
|------|----------|
| `collected_blogs_count < 3` | 계속 블로그 수집 및 분석 |
| `collected_blogs_count = 3` | **중간 평가** → `info_count` 확인 → 조기 종료 또는 목표 조정 |
| `3 < collected_blogs_count < max_blogs_target` | 계속 수집 |
| `collected_blogs_count = max_blogs_target` | 수집 완료 → 다음 장소로 이동 |
| 검색 결과 자체가 부족 | 가능한 개수로 진행 + 사용자 요청 시 추가 조회 가능 |

**특징**: 
- 동적 목표 조정 (3-7개)
- 정보 충분 시 효율적 조기 종료
- 정보 부족 시 적극적 추가 수집

#### 3. `relevance_status` (연관성 평가 결과)

| 값 | 의미 | Agent 행동 |
|---|------|----------|
| "pass" | 통과 | 해당 장소 유지 |
| "fail" | 미달 | 해당 장소 제외 후보 |

**연관성 평가 기준**:
- 5개 블로그 중 **1개 이상**의 블로그에서 사용자 키워드가 **블로그당 2회 이상** 언급
- 해당 음식점 리뷰여야 함 (다른 가게 언급 제외)
- 문맥상 적절해야 함 (키워드만 일치하는 것 제외)

#### 4. 통과 장소 개수 (연관성 평가 후)

| 통과 개수 | Agent 행동 |
|---------|----------|
| ≥ 3개 | 종합 분석 진행 (특색 판단 → 점수 계산) |
| < 3개 | 재검색 1회 시도 |

**재검색 프로세스**:
1. LLM에게 전달:
   - 초기 쿼리: "강남역 파스타"
   - 위치 키워드: "강남역"
   - 음식 키워드: "파스타"
   - 미달 장소들: [이름, 주소(예: 서초구, 송파구), 미달 이유]
   - 통과 장소들: [이름, 주소(예: 강남구)]
   
2. LLM이 **위치 범위 확대**하여 쿼리 재작성:
   ```
   프롬프트 예시:
   "위치 키워드의 범위를 확대하여 네이버 지도 검색 쿼리를 재작성하세요.
   
   전략: 역 단위 → 구/동 단위로 확대
   예시:
   - 강남역 → 강남 또는 역삼/논현
   - 홍대입구역 → 홍대 또는 마포/서교동
   - 신촌역 → 신촌 또는 서대문
   
   현재 초기 쿼리: '강남역 파스타'
   통과 장소 주소: 강남구 역삼동
   미달 장소 주소: 서초구 서초동, 송파구 잠실동
   
   재작성 쿼리: "
   ```
   
   LLM 출력 예: "강남 파스타" 또는 "역삼 파스타"

3. 네이버 지도 API 재검색 → 새 장소들
4. 새 장소들 블로그 분석 → 연관성 재평가
5. 여전히 3개 미만이어도 진행 (재검색은 1회만)

#### 5. `retry_count` (재검색 횟수)

| 값 | Agent 행동 |
|---|----------|
| 0 | 재검색 가능 |
| 1 | 재검색 불가 (최대 1회 제한) |

#### 6. 기타 상태 (기록/추적용)

- `elapsed_time`: 기록용, 행동 변경 안 함
- `current_place_index`: 진행 상황 추적용
- `total_places`: 진행 상황 추적용

### 3.3 상태가 없을 때 발생하는 문제

| 상태 | 없을 때 문제 |
|------|------------|
| `collected_blogs_count` | 언제 다음 장소로 이동할지 판단 불가 |
| `max_blogs_target` | 정보 부족 시 목표 확장 불가 |
| `info_count` | 조기 종료/목표 확장 판단 불가 |
| `collected_info` | 블로그별 정보 추적 불가, 디버깅 불가 |
| `raw_text` | 분석 근거 확인 불가, 재분석 불가 |
| `relevance_status` | 연관성 낮은 장소 필터링 불가 |
| `retry_count` | 무한 재검색 가능성 |
| `all_places` | 5개 장소 동시 관리 불가 |

---

## 4. 판단 로직 설계

### 4.1 특색 판단 로직 (의사결정 2)

**입력**: 5개 블로그의 `메뉴` 필드

**계산 방법**: 블로그 비율 기준

**의사 코드**:
```python
def judge_specialty(blogs):
    # 1. 메뉴별 언급 블로그 카운트
    menu_count = {}
    for blog in blogs:
        for menu in blog["메뉴"]:
            if menu not in menu_count:
                menu_count[menu] = 0
            menu_count[menu] += 1
    
    # 2. 블로그 비율 계산
    total_blogs = len(blogs)
    menu_ratio = {menu: count / total_blogs for menu, count in menu_count.items()}
    
    # 3. 특색 판단
    # 규칙 1: 50% 이상 블로그에서 언급된 메뉴들
    specialty = [menu for menu, ratio in menu_ratio.items() if ratio >= 0.5]
    
    if specialty:
        return ", ".join(specialty)
    
    # 규칙 2: 50% 미만이면 2개 이상 블로그에서 언급된 것 중 최고 (동률 전부)
    high_mentions = {menu: count for menu, count in menu_count.items() if count >= 2}
    
    if not high_mentions:
        return "특색 정보 없음"
    
    max_count = max(high_mentions.values())
    specialty = [menu for menu, count in high_mentions.items() if count == max_count]
    
    return ", ".join(specialty)
```

**예시**:
- 크림파스타(4/5=80%), 토마토파스타(3/5=60%) → "크림파스타, 토마토파스타"
- 크림파스타(2/5=40%), 토마토파스타(2/5=40%) → "크림파스타, 토마토파스타"
- 크림파스타(2/5=40%), 토마토파스타(1/5=20%) → "크림파스타"
- 모두 1회씩 → "특색 정보 없음"

### 4.2 점수 계산 로직 (의사결정 3)

**입력**: 5개 블로그의 항목별 판단 (긍정/부정/None)

**계산 방법**: 블로그별 판단 → 단순 합산

**의사 코드**:
```python
def calculate_score(blogs, item):
    base_score = 500
    positive_count = 0
    negative_count = 0
    
    for blog in blogs:
        judgment = blog[item]  # 긍정/부정/None
        if judgment == "긍정":
            positive_count += 1
        elif judgment == "부정":
            negative_count += 1
        # None은 카운트 안 함
    
    score = base_score + (positive_count * 100) - (negative_count * 100)
    
    # 범위 제한
    score = max(0, min(1000, score))
    
    return score

def calculate_total_score(scores):
    weights = {
        "맛": 0.4,
        "가격": 0.2,
        "서비스": 0.2,
        "양": 0.1,
        "웨이팅": 0.1
    }
    
    total = sum(scores[item] * weights[item] for item in weights.keys())
    
    return int(total)
```

**예시**:
- 맛: 긍정 3개, 부정 1개, 없음 1개 → 500 + 300 - 100 = 700점
- 가격: 긍정 2개 → 500 + 200 = 700점
- 종합: (700×0.4) + (700×0.2) + (500×0.2) + (500×0.1) + (500×0.1) = 640점

### 4.3 연관성 평가 로직 (검증 단계)

**입력**: 블로그 5개, 사용자 키워드

**판단 기준**: 블로그당 키워드 2회 이상 언급한 블로그가 1개 이상

**의사 코드**:
```python
def evaluate_relevance(blogs, keyword):
    qualified_blogs = 0
    
    for blog in blogs:
        # raw_text에서 키워드 출현 횟수
        keyword_count = blog["raw_text"].count(keyword)
        
        # 해당 음식점 리뷰인지 (LLM 판단 필요)
        is_relevant_restaurant = check_restaurant_relevance(blog, place_name)
        
        # 문맥상 적절한지 (LLM 판단 필요)
        is_contextual = check_context_relevance(blog, keyword)
        
        if keyword_count >= 2 and is_relevant_restaurant and is_contextual:
            qualified_blogs += 1
    
    if qualified_blogs >= 1:
        return "pass", ""
    else:
        return "fail", f"키워드 '{keyword}' 언급 부족"
```

---

## 5. Agent 플로우 및 순환 구조

### 5.1 전체 실행 플로우

```
[사용자 입력]
    ↓
┌─────────────────────────────────────────┐
│ 1. 초기 노드: 검수 및 최적화            │
│  - 부적절 여부 체크                      │
│  - 서비스 연관성 체크                    │
│  - 위치/음식 키워드 추출                 │
│  - 좌표 → 주소 변환 (필요 시)           │
│  - 네이버 지도 검색 쿼리 최적화          │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 2. 네이버 지도 API 검색                 │
│  → 5개 장소 받음 (이름, 주소, URL)       │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 3-7. 장소별 블로그 수집 및 분석 (개별)  │
│                                          │
│ For each 장소:                          │
│   ├─ 네이버 지도 URL → 블로그 리뷰 크롤링│
│   ├─ 블로그 1 분석 → collected_info[0]  │
│   ├─ 블로그 2 분석 → collected_info[1]  │
│   ├─ 블로그 3 분석 → collected_info[2]  │
│   │                                      │
│   ├─ [중간 평가] collected_blogs_count=3│
│   │   ├─ info_count ≥ 3?                │
│   │   │   Yes → 조기 종료 (다음 장소로) │
│   │   │   No → 계속                     │
│   │   └─ info_count < 2?                │
│   │       Yes → max_blogs_target = 7    │
│   │       No → max_blogs_target = 5     │
│   │                                      │
│   ├─ 블로그 4-5 (또는 7) 분석           │
│   └─ collected_blogs_count =            │
│      max_blogs_target                   │
│      → 다음 장소로 이동                  │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 8. 5개 장소 모두 수집 완료               │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 9. 연관성 평가 (각 장소별)              │
│  - 기준: 블로그당 키워드 2회 이상 언급한 │
│    블로그가 1개 이상                     │
│  - 통과/미달 판정                        │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 10. 통과 장소 개수 확인                 │
└─────────────────────────────────────────┘
    ↓
    ├─── ≥ 3개 ────→ [11. 종합 분석]
    │
    └─── < 3개 ────→ [10-A. 재검색 프로세스]
                          ↓
                    ┌─────────────────┐
                    │ LLM 쿼리 재작성  │
                    │ (위치 범위 확대) │
                    │ 예: 강남역→강남  │
                    └─────────────────┘
                          ↓
                    ┌─────────────────┐
                    │ 네이버 지도      │
                    │ API 재검색       │
                    └─────────────────┘
                          ↓
                    ┌─────────────────┐
                    │ 새 장소들        │
                    │ 블로그 분석      │
                    └─────────────────┘
                          ↓
                    retry_count++
                          ↓
                    [9. 연관성 재평가]
                          ↓
                    retry_count = 1?
                          ↓
                    Yes → [11. 종합 분석]
                          (3개 미만이어도 진행)
    
[11. 종합 분석]
    ↓
┌─────────────────────────────────────────┐
│ 11. 각 장소별 특색 판단                 │
│  - 50% 이상 블로그 언급                 │
│  - 없으면 2개 이상 중 최고 (동률 전부)  │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 12. 각 장소별 점수 계산                 │
│  - 5개 항목별 점수                      │
│  - 가중치 합산                          │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 13. 최종 결과 출력                      │
│  - 통과한 장소들 비교표                 │
│  - 제외된 장소 정보 (이유 포함)         │
└─────────────────────────────────────────┘
```

### 5.2 순환 구조 및 탈출 조건

#### 순환 1: 블로그 수집 (장소별)

**루프**: 블로그 분석 (개별) → `collected_blogs_count++` → 목표 미달이면 반복

**중간 평가 (3개 시점)**:
- `info_count ≥ 3` → 조기 종료 (탈출)
- `info_count < 2` → `max_blogs_target = 7` (목표 확장)
- 그 외 → `max_blogs_target = 5` (기본 유지)

**탈출 조건**:
- `collected_blogs_count = 3` + `info_count ≥ 3` (조기 종료)
- 또는 `collected_blogs_count = max_blogs_target` (목표 달성)
- 또는 검색 결과 부족 (가능한 개수로 진행)

**최대 반복**: 3-7회 (동적 조정)

#### 순환 2: 재검색 (연관성 미달 시)

**루프**: 연관성 평가 → 3개 미만 → LLM 쿼리 재작성 (위치 범위 확대) → 지도 API 재검색 → 블로그 분석 → 연관성 재평가

**재작성 전략**: 위치 범위 확대
- 예: "강남역" → "강남" 또는 "역삼/논현"
- LLM이 통과/미달 장소 주소 분석하여 최적 범위 선택

**탈출 조건**:
- 통과 장소 ≥ 3개
- 또는 `retry_count = 1` (최대 1회 제한)

**최대 반복**: 1회

**무한 루프 방지**: `retry_count` 제한

### 5.3 주요 분기점

| 분기점 | 조건 | 경로 |
|-------|------|------|
| 블로그 3개 수집 후 | `info_count ≥ 3` | → 조기 종료 (다음 장소) |
| 블로그 3개 수집 후 | `info_count < 2` | → 목표 확장 (max = 7) |
| 블로그 3개 수집 후 | `info_count = 2` | → 기본 목표 유지 (max = 5) |
| 블로그 수집 완료 | `collected_blogs_count = max_blogs_target` | → 다음 장소 |
| 5개 장소 수집 완료 | `current_place_index = 5` | → 연관성 평가 |
| 연관성 평가 후 | 통과 ≥ 3개 | → 종합 분석 |
| 연관성 평가 후 | 통과 < 3개, retry_count = 0 | → 재검색 (위치 범위 확대) |
| 연관성 평가 후 | 통과 < 3개, retry_count = 1 | → 종합 분석 (그대로 진행) |

---

## 6. 3단계 개선 사항 요약 (v0.3.1)

### 개선 배경
초기 3단계 설계에 대한 AI Agent Service 컨셉 부합도 평가 결과:
- **초기 점수**: 68/100점 (보완 후 실행 권장)
- **주요 문제**: 자율 판단이 행동에 영향을 주지 않음 (판단 무시)

### 주요 개선 사항

#### 1. `info_count` 기반 동적 블로그 수집 전략 ⭐⭐⭐
**Before**: 무조건 5개 수집 (판단 무시)
```python
info_count ≥ 3 → is_sufficient = True (기록만)
→ 블로그 5개 수집 (행동 변경 없음)
```

**After**: 판단 결과가 행동에 직접 영향
```python
# 블로그 3개 분석 후 중간 평가
if info_count ≥ 3:
    → 조기 종료 (비용 절감)
elif info_count < 2:
    → 목표 확장 (7개까지, 정보 품질 향상)
else:
    → 기본 목표 유지 (5개)
```

**효과**:
- Agent 자율 판단 → 행동 변경 ✅
- 비용 최적화 (불필요한 수집 감소)
- 정보 품질 보장 (부족 시 확장)

#### 2. 재검색 전략 명확화 (위치 범위 확대) ⭐⭐
**Before**: LLM이 다양한 방법으로 재작성 (불명확)

**After**: 위치 범위 확대 전략으로 집중
```
전략: 역 단위 → 구/동 단위로 확대
예: "강남역" → "강남" 또는 "역삼/논현"
```

**LLM 프롬프트 명확화**:
- 통과/미달 장소 주소 분석
- 실효성 높은 위치 범위 재작성

**효과**:
- 재검색 성공률 향상
- 명확한 전략 (개발 구현 용이)

#### 3. 조기 종료 로직 추가 ⭐
**Before**: 블로그 5개까지 무조건 수집

**After**: 블로그 3개 시점에 중간 평가
- 정보 충분 시 조기 종료
- 효율성 증가

### 개선 후 예상 점수
- **자율 판단**: 2.5/5 → **4/5** (⬆ +1.5점)
- **반복 개선**: 3.5/5 → **4/5** (⬆ +0.5점)
- **순환 구조**: 4/5 → **4.5/5** (⬆ +0.5점)

**총점**: 68/100 → **78/100점** (⬆ +10점)

**판정**: 보완 후 실행 → **보완 완료, 실행 가능** ✅

---

## 다음 단계 예정

**4단계**: Agent 오케스트레이션 및 도구 설계
- LangGraph 노드 정의
- 조건부 엣지 설계
- 도구 목록 및 사용 조건
- 기술 스택 결정

---

## 변경 이력

| 날짜 | 버전 | 변경 내용 | 작성자 |
|------|------|-----------|--------|
| 2026-01-07 | 0.1 | 1단계 완료: 핵심 파악 및 Agent 필요성 검증 | AI Agent + 사용자 |
| 2026-01-07 | 0.2 | 2단계 완료: Agent 핵심 능력 및 MVP 정의 | AI Agent + 사용자 |
| 2026-01-07 | 0.3 | 3단계 완료: Agent 상태 및 판단 로직 설계 | AI Agent + 사용자 |
| 2026-01-07 | 0.3.1 | 3단계 개선: Agent다움 강화 (자율 판단 → 행동 반영, 재검색 전략 명확화) | AI Agent + 사용자 |

