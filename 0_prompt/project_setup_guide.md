# í”„ë¡œì íŠ¸ ìƒì„± ì§€ì‹œë¬¸ì„œ

## í”„ë¡œì íŠ¸ ê°œìš”

íŒŒì´ì¬ì„ ì´ìš©í•œ ë°±ì—”ë“œ í”„ë¡œì íŠ¸ë¥¼ ê°œë°œí•©ë‹ˆë‹¤. LangGraphë¥¼ ì´ìš©í•œ AI Agent í™œìš© í”„ë¡œì íŠ¸ì´ë©°, ê¸°ë³¸ì ì¸ í•„ìˆ˜ í•­ëª©ì„ í¬í•¨í•œ FastAPI POST ì˜ˆì œë¥¼ ë¼ìš°íŒ…ë˜ëŠ” êµ¬ì¡°ë¡œ ë§Œë“­ë‹ˆë‹¤.

## ê¸°ìˆ  ìŠ¤íƒ

- **FastAPI**: ê³ ì„±ëŠ¥ ì›¹ í”„ë ˆì„ì›Œí¬
- **LangGraph**: AI Agent ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- **LangChain**: LLM í†µí•©
- **OpenAI**: GPT ëª¨ë¸
- **Uvicorn**: ASGI ì„œë²„
- **Pydantic**: ë°ì´í„° ê²€ì¦ ë° ì„¤ì • ê´€ë¦¬

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
í”„ë¡œì íŠ¸ëª…/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # ì„¤ì • ê´€ë¦¬ (í™˜ê²½ ë³€ìˆ˜)
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ agent.py           # LangGraph Agent êµ¬í˜„
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ agent_router.py    # Agent ê´€ë ¨ ë¼ìš°í„°
â”‚       â””â”€â”€ health_router.py   # Health check ë¼ìš°í„°
â”œâ”€â”€ main.py                    # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”œâ”€â”€ requirements.txt           # Python íŒ¨í‚¤ì§€ ì˜ì¡´ì„±
â”œâ”€â”€ .env.example              # í™˜ê²½ ë³€ìˆ˜ ì˜ˆì œ
â”œâ”€â”€ .gitignore                # Git ë¬´ì‹œ íŒŒì¼
â””â”€â”€ README.md                 # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```

## í•„ìˆ˜ íŒŒì¼ ìƒì„±

### 1. requirements.txt

```txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
pydantic-settings==2.1.0
langgraph==0.0.20
langchain==0.1.0
langchain-openai==0.0.2
langchain-core==0.1.10
python-dotenv==1.0.0
python-multipart==0.0.6
```

### 2. app/config.py

```python
from pydantic_settings import BaseSettings
from typing import Optional


class Settings(BaseSettings):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •"""
    openai_api_key: str
    host: str = "0.0.0.0"
    port: int = 8000
    debug: bool = True
    
    class Config:
        env_file = ".env"
        case_sensitive = False


settings = Settings()
```

### 3. app/agents/agent.py

LangGraphë¥¼ ì‚¬ìš©í•œ AI Agent êµ¬í˜„:

```python
from typing import TypedDict, Annotated
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
import operator
from app.config import settings


class AgentState(TypedDict):
    """Agent ìƒíƒœ ì •ì˜"""
    messages: Annotated[list, add_messages]
    user_query: str
    response: str


class LangGraphAgent:
    """LangGraphë¥¼ ì‚¬ìš©í•œ AI Agent"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7,
            api_key=settings.openai_api_key
        )
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """LangGraph ê·¸ë˜í”„ êµ¬ì„±"""
        workflow = StateGraph(AgentState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("process_query", self._process_query)
        workflow.add_node("generate_response", self._generate_response)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("process_query")
        workflow.add_edge("process_query", "generate_response")
        workflow.add_edge("generate_response", END)
        
        return workflow.compile()
    
    def _process_query(self, state: AgentState) -> AgentState:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬"""
        # ì¿¼ë¦¬ ì „ì²˜ë¦¬ ë˜ëŠ” ê²€ì¦ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
        return state
    
    def _generate_response(self, state: AgentState) -> AgentState:
        """LLMì„ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±"""
        user_query = state.get("user_query", "")
        
        # LLM í˜¸ì¶œ
        response = self.llm.invoke(user_query)
        
        state["response"] = response.content if hasattr(response, 'content') else str(response)
        return state
    
    async def process(self, user_query: str) -> str:
        """Agent ì‹¤í–‰"""
        initial_state = {
            "messages": [],
            "user_query": user_query,
            "response": ""
        }
        
        result = await self.graph.ainvoke(initial_state)
        return result.get("response", "")


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
agent = LangGraphAgent()
```

### 4. app/routers/agent_router.py

Agent ê´€ë ¨ POST ì—”ë“œí¬ì¸íŠ¸:

```python
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from app.agents.agent import agent

router = APIRouter(prefix="/api/v1/agent", tags=["agent"])


class AgentRequest(BaseModel):
    """Agent ìš”ì²­ ëª¨ë¸"""
    query: str
    max_length: int = 500


class AgentResponse(BaseModel):
    """Agent ì‘ë‹µ ëª¨ë¸"""
    response: str
    query: str
    success: bool = True


@router.post("/chat", response_model=AgentResponse)
async def chat_with_agent(request: AgentRequest):
    """
    AI Agentì™€ ëŒ€í™”í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    - **query**: ì‚¬ìš©ì ì§ˆë¬¸ ë˜ëŠ” ìš”ì²­
    - **max_length**: ìµœëŒ€ ì‘ë‹µ ê¸¸ì´ (ê¸°ë³¸ê°’: 500)
    """
    try:
        if not request.query or len(request.query.strip()) == 0:
            raise HTTPException(
                status_code=400,
                detail="Query cannot be empty"
            )
        
        # Agent ì‹¤í–‰
        response_text = await agent.process(request.query)
        
        # ì‘ë‹µ ê¸¸ì´ ì œí•œ
        if len(response_text) > request.max_length:
            response_text = response_text[:request.max_length] + "..."
        
        return AgentResponse(
            response=response_text,
            query=request.query,
            success=True
        )
    
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Agent processing failed: {str(e)}"
        )


@router.post("/analyze", response_model=AgentResponse)
async def analyze_text(request: AgentRequest):
    """
    í…ìŠ¤íŠ¸ ë¶„ì„ì„ ìœ„í•œ ì—”ë“œí¬ì¸íŠ¸
    
    - **query**: ë¶„ì„í•  í…ìŠ¤íŠ¸
    """
    try:
        analysis_query = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”: {request.query}"
        response_text = await agent.process(analysis_query)
        
        return AgentResponse(
            response=response_text,
            query=request.query,
            success=True
        )
    
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Analysis failed: {str(e)}"
        )
```

### 5. app/routers/health_router.py

Health check ë¼ìš°í„°:

```python
from fastapi import APIRouter
from pydantic import BaseModel
from datetime import datetime

router = APIRouter(tags=["health"])


class HealthResponse(BaseModel):
    """Health check ì‘ë‹µ ëª¨ë¸"""
    status: str
    timestamp: str
    service: str


@router.get("/health")
async def health_check():
    """
    ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸
    """
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now().isoformat(),
        service="now_what_be"
    )


@router.get("/")
async def root():
    """
    ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸
    """
    return {
        "message": "Welcome to Now What Backend API",
        "version": "1.0.0",
        "docs": "/docs"
    }
```

### 6. main.py

FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì :

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.routers import agent_router, health_router
from app.config import settings

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Now What Backend API",
    description="LangGraphë¥¼ í™œìš©í•œ AI Agent ë°±ì—”ë“œ ì„œë¹„ìŠ¤",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS í—ˆìš© ì˜¤ë¦¬ì§„ ì„¤ì •
# ì°¸ê³ : Postman, cURL ë“± ë¸Œë¼ìš°ì €ê°€ ì•„ë‹Œ ë„êµ¬ëŠ” CORS ì •ì±…ì˜ ì˜í–¥ì„ ë°›ì§€ ì•ŠìŠµë‹ˆë‹¤.
# ì•„ë˜ ì„¤ì •ì€ ë¸Œë¼ìš°ì € ê¸°ë°˜ í´ë¼ì´ì–¸íŠ¸(ì›¹ ì•±, Swagger UI ë“±)ë¥¼ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.
ALLOWED_ORIGINS = [
    "http://localhost:3000",  # React ê¸°ë³¸ í¬íŠ¸
    "http://localhost:5173",  # Vite ê¸°ë³¸ í¬íŠ¸
    "http://localhost:8080",  # Vue ê¸°ë³¸ í¬íŠ¸
    "http://127.0.0.1:3000",
    "http://127.0.0.1:5173",
    "http://127.0.0.1:8080",
]

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,  # ë¸Œë¼ìš°ì € ê¸°ë°˜ í´ë¼ì´ì–¸íŠ¸ìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(health_router.router)
app.include_router(agent_router.router)


@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰"""
    print("ğŸš€ Now What Backend API ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“š API ë¬¸ì„œ: http://{settings.host}:{settings.port}/docs")


@app.on_event("shutdown")
async def shutdown_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    print("ğŸ‘‹ Now What Backend API ì„œë²„ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host=settings.host,
        port=settings.port,
        reload=settings.debug
    )
```

### 7. __init__.py íŒŒì¼ë“¤

ëª¨ë“  íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ì— ë¹ˆ `__init__.py` íŒŒì¼ ìƒì„±:
- `app/__init__.py`
- `app/agents/__init__.py`
- `app/routers/__init__.py`

### 8. .env.example

```env
# OpenAI API Key
OPENAI_API_KEY=your_openai_api_key_here

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=True
```

## í•µì‹¬ ìš”êµ¬ì‚¬í•­

### 1. LangGraphë¥¼ ì´ìš©í•œ AI Agent
- `StateGraph`ë¥¼ ì‚¬ìš©í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±
- ë…¸ë“œ ê¸°ë°˜ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
- ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì›

### 2. FastAPI POST ì˜ˆì œ
- `/api/v1/agent/chat` - AI Agentì™€ ëŒ€í™”
- `/api/v1/agent/analyze` - í…ìŠ¤íŠ¸ ë¶„ì„
- Pydantic ëª¨ë¸ì„ ì‚¬ìš©í•œ ìš”ì²­/ì‘ë‹µ ê²€ì¦

### 3. ë¼ìš°íŒ… êµ¬ì¡°
- ëª¨ë“ˆí™”ëœ ë¼ìš°í„° êµ¬ì¡° (`app/routers/`)
- ê° ë¼ìš°í„°ëŠ” ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ ê´€ë¦¬
- `main.py`ì—ì„œ í†µí•© ë“±ë¡

### 4. ê¸°ë³¸ í•„ìˆ˜ í•­ëª©
- í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ (Pydantic Settings)
- CORS ì„¤ì •
- Health check ì—”ë“œí¬ì¸íŠ¸
- ì—ëŸ¬ í•¸ë“¤ë§
- API ë¬¸ì„œ ìë™ ìƒì„± (Swagger UI)

## ì‹¤í–‰ ë°©ë²•

1. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”:
```bash
python -m venv venv
source venv/bin/activate  # macOS/Linux
# ë˜ëŠ”
venv\Scripts\activate  # Windows
```

2. íŒ¨í‚¤ì§€ ì„¤ì¹˜:
```bash
pip install -r requirements.txt
```

3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:
`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  `OPENAI_API_KEY`ë¥¼ ì„¤ì •

4. ì„œë²„ ì‹¤í–‰:
```bash
python main.py
```

## API ì—”ë“œí¬ì¸íŠ¸

### POST /api/v1/agent/chat
AI Agentì™€ ëŒ€í™”í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸

**Request Body:**
```json
{
  "query": "ì•ˆë…•í•˜ì„¸ìš”",
  "max_length": 500
}
```

**Response:**
```json
{
  "response": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
  "query": "ì•ˆë…•í•˜ì„¸ìš”",
  "success": true
}
```

### POST /api/v1/agent/analyze
í…ìŠ¤íŠ¸ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸

**Request Body:**
```json
{
  "query": "ë¶„ì„í•  í…ìŠ¤íŠ¸"
}
```

### GET /health
ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸

### GET /
ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸

## ì°¸ê³ ì‚¬í•­

- ëª¨ë“  ë¼ìš°í„°ëŠ” `app/routers/` ë””ë ‰í† ë¦¬ì— ëª¨ë“ˆí™”ë˜ì–´ ìˆìŒ
- AgentëŠ” `app/agents/agent.py`ì— ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ êµ¬í˜„
- ì„¤ì •ì€ `app/config.py`ì—ì„œ ì¤‘ì•™ ê´€ë¦¬
- CORSëŠ” ë¸Œë¼ìš°ì € ê¸°ë°˜ í´ë¼ì´ì–¸íŠ¸ë¥¼ ìœ„í•´ ì„¤ì • (Postmanì€ ì˜í–¥ ì—†ìŒ)

